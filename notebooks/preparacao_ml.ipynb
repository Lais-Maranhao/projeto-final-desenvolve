{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparação de Dados para Machine Learning\n",
    "\n",
    "Este notebook prepara o dataset para treinar um modelo de machine learning. As etapas seguem o `guia_preparacao_machine_learning.md`.\n",
    "\n",
    "Etapas:\n",
    "1. Limpeza e pré-processamento (valores ausentes, coluna 'Age').\n",
    "2. Remoção de duplicatas.\n",
    "3. Tratamento de outliers (IQR).\n",
    "4. Transformação de variáveis assimétricas (log).\n",
    "5. Remoção de variáveis altamente correlacionadas.\n",
    "6. Agrupamento de categorias raras.\n",
    "7. Encoding de variáveis categóricas (One-Hot Encoding).\n",
    "8. Normalização de variáveis numéricas (StandardScaler).\n",
    "\n",
    "O resultado será salvo em `data/train_data_ml_v2.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [ "## 1. Importação das Bibliotecas" ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [ "## 2. Carregamento dos Dados" ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [ "df = pd.read_csv('../data/train_data.csv')" ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Limpeza e Pré-processamento\n",
    "\n",
    "Antes de seguir o guia, realizamos uma limpeza inicial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [ "### 3.1. Tratamento de Valores Ausentes" ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Bed Grade'] = df['Bed Grade'].fillna(df['Bed Grade'].mode()[0])\n",
    "df['City_Code_Patient'] = df['City_Code_Patient'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Limpeza da Coluna 'Age'\n",
    "\n",
    "A coluna 'Age' está em formato de string ('51-60'). Convertemos para um valor numérico usando a média do intervalo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_to_numeric(age_range):\n",
    "    if isinstance(age_range, str):\n",
    "        low, high = age_range.split('-')\n",
    "        return (int(low) + int(high)) / 2\n",
    "    return age_range\n",
    "\n",
    "df['Age'] = df['Age'].apply(age_to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [ "## 4. Passos do Guia de Preparação" ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [ "### 4.1. Remoção de Duplicatas" ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [ "df = df.drop_duplicates()" ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [ "### 4.2. Tratamento de Outliers (IQR)" ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_original = df.select_dtypes(include=np.number).columns.tolist()\n",
    "for col in num_cols_original:\n",
    "    if col not in ['case_id', 'patientid']:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lim_inf = Q1 - 1.5 * IQR\n",
    "        lim_sup = Q3 + 1.5 * IQR\n",
    "        df = df[(df[col] >= lim_inf) & (df[col] <= lim_sup)]"
   ]
  },
    {
   "cell_type": "markdown",
   "metadata": {},
   "source": [ "### 4.3. Transformação de Variáveis Assimétricas" ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed_cols = ['Admission_Deposit'] # Exemplo\n",
    "for col in skewed_cols:\n",
    "    if col in df.columns:\n",
    "      df[col] = np.log1p(df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [ "### 4.4. Remoção de Variáveis Altamente Correlacionadas" ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_clean = df.select_dtypes(include=np.number).columns.tolist()\n",
    "corr_matrix = df[num_cols_clean].corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "df = df.drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [ "### 4.5. Agrupamento de Categorias Raras" ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in cat_cols:\n",
    "    if col != 'Stay': # Não agrupar a variável alvo\n",
    "        freq = df[col].value_counts(normalize=True)\n",
    "        raras = freq[freq < 0.01].index\n",
    "        if len(raras) > 0:\n",
    "            df[col] = df[col].replace(raras, 'OUTRA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [ "### 4.6. Encoding de Variáveis Categóricas (One-Hot)" ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'Stay'\n",
    "categorical_features = df.select_dtypes(include=['object']).columns.drop(target_col, errors='ignore')\n",
    "df = pd.get_dummies(df, columns=categorical_features, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [ "### 4.7. Normalização das Variáveis Numéricas" ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = df.select_dtypes(include=np.number).columns.drop(['case_id', 'patientid'], errors='ignore')\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [ "## 5. Salvando o Dataset Processado" ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [ "df.to_csv('../data/train_data_ml_v2.csv', index=False)" ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
