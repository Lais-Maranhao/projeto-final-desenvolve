{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f000105",
   "metadata": {},
   "source": [
    "# Dataset limpo para análise exploratória\n",
    "Este notebook gera e salva um arquivo com o dataset limpo, sem normalização ou encoding, para facilitar análises exploratórias. Separar os arquivos por finalidade (análise vs machine learning) torna o projeto mais organizado e flexível."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b677d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação das bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ed95905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura do dataset original\n",
    "train_data_raw = pd.read_csv('../data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e62aff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpeza básica: duplicatas, outliers, variáveis correlacionadas (manual), categorias raras\n",
    "train_data_limpo = train_data_raw.drop_duplicates()\n",
    "num_cols = train_data_limpo.select_dtypes(include=['float64', 'int64']).columns\n",
    "for col in num_cols:\n",
    "    Q1 = train_data_limpo[col].quantile(0.25)\n",
    "    Q3 = train_data_limpo[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lim_inf = Q1 - 1.5 * IQR\n",
    "    lim_sup = Q3 + 1.5 * IQR\n",
    "    train_data_limpo = train_data_limpo[(train_data_limpo[col] >= lim_inf) & (train_data_limpo[col] <= lim_sup)]\n",
    "# Visualize a matriz de correlação para decidir manualmente quais colunas remover\n",
    "print(train_data_limpo[num_cols].corr())\n",
    "# Exemplo: para remover manualmente, use algo assim:\n",
    "# train_data_limpo = train_data_limpo.drop(columns=['coluna1', 'coluna2'])\n",
    "# cat_cols = train_data_limpo.select_dtypes(include=['object', 'category']).columns\n",
    "for col in cat_cols:\n",
    "    freq = train_data_limpo[col].value_counts(normalize=True)\n",
    "    raras = freq[freq < 0.01].index\n",
    "    train_data_limpo[col] = train_data_limpo[col].replace(raras, 'OUTRA')\n",
    "train_data_limpo.to_csv('../data/train_data_limpo.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a253292",
   "metadata": {},
   "source": [
    "## Por que separar os arquivos?\n",
    "Separar os arquivos por finalidade (análise exploratória, machine learning, etc) facilita a organização do projeto, evita confusões e permite que diferentes etapas sejam realizadas de forma independente. Assim, é possível garantir que cada equipe ou pessoa trabalhe com o dado mais adequado para sua tarefa, sem misturar transformações específicas de modelagem com dados para análise geral."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
